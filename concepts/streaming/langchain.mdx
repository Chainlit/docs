---
title: LangChain Streaming
---

Chainlit supports LangChain's stream API natively. To use streaming just pass `streaming=True` when instantiating the LLM:

```python Code Example
llm = OpenAI(temperature=0, streaming=True)
```

Also make sure to pass a [callback handler](api-reference/langchain/callbacks) to your chain or agent run.

See [here](api-reference/langchain/callbacks#final-answer-streaming) for final answer streaming.
