---
title: "Step Class"
---

The `Step` class is a Python Context Manager that can be used to create steps in your chainlit app. The step is created when the context manager is entered and is updated to the client when the context manager is exited.

## Parameters

<ParamField path="name" type="str" optional>
  The name of the step. Default to the name of the decorated function.
</ParamField>
<ParamField path="type" type="Enum" default="undefined" optional>
  The type of the step, useful for monitoring and debugging.
</ParamField>
<ParamField path="elements" type="List[Element]" optional>
  Elements to attach to the step.
</ParamField>
<ParamField path="root" type="bool" default="False" optional>
  By default the step will be nested under the previous step/message. Set this
  to `True` to make it a root step.
</ParamField>
<ParamField path="language" type="str" optional>
  Language of the output. See
  https://react-code-blocks-rajinwonderland.vercel.app/?path=/story/codeblock--supported-languages
  for a list of supported languages.
</ParamField>
<ParamField path="show_input" type="Union[bool, str]" default="False" optional>
  By default only the output of the step is shown. Set this to `True` to also
  show the input. You can also set this to a language like `json` or `python` to
  syntax highlight the input.
</ParamField>

## Send a Step

```python
import chainlit as cl

@cl.on_message
async def main():
    async with cl.Step(name="Test") as step:
        # Step is sent as soon as the context manager is entered
        step.input = "hello"
        step.output = "world"

    # Step is updated when the context manager is exited
```

## Stream the Output

```python
from openai import AsyncOpenAI

import chainlit as cl

client = AsyncOpenAI()

@cl.on_message
async def main(msg: cl.Message):

    # Whether to nest the step under the user message
    root = True

    async with cl.Step(name="gpt4", type="llm", root=root) as step:
        step.input = msg.content

        stream = await client.chat.completions.create(
            messages=[{"role": "user", "content": msg.content}],
            stream=True,
            model="gpt-4",
            temperature=0,
        )

        async for part in stream:
            delta = part.choices[0].delta
            if delta.content:
                # Stream the output of the step
                await step.stream_token(delta.content)
```

## Nest Steps

To nest steps, simply create a step inside another step.

```python
import chainlit as cl


@cl.on_chat_start
async def main():
    async with cl.Step(name="Parent step") as parent_step:
        parent_step.input = "Parent step input"

        async with cl.Step(name="Child step") as child_step:
            child_step.input = "Child step input"
            child_step.output = "Child step output"

        parent_step.output = "Parent step output"
```

## Update a Step

```python
import chainlit as cl


@cl.on_chat_start
async def main():
    async with cl.Step(name="Parent step") as step:
        step.input = "Parent step input"
        step.output = "Parent step output"

    await cl.sleep(2)

    step.output = "Parent step output updated"
    await step.update()
```

## Remove a Step

```python
import chainlit as cl


@cl.on_chat_start
async def main():
    async with cl.Step(name="Parent step") as step:
        step.input = "Parent step input"
        step.output = "Parent step output"

    await cl.sleep(2)

    await step.remove()
```
