---
title: "llama_index_factory"
---

Plug and play decorator for the Llama Index library.

The decorated function should return a `QueryEngine` or `ChatEngine` instance. One instance per user session is created and cached. The per user instance is called every time a new message is received.

### Usage

```python Code Example
import os
from llama_index import VectorStoreIndex, SimpleDirectoryReader
import openai
import chainlit as cl

openai.api_key = os.environ.get("OPENAI_API_KEY")


@cl.llama_index_factory
def factory():
    documents = SimpleDirectoryReader("data").load_data()
    index = VectorStoreIndex.from_documents(documents)
    query_engine = index.as_query_engine()
    return query_engine
```
