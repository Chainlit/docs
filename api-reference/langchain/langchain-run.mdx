---
title: "langchain_run"
---

This document demonstrates how to override the default behavior of a LangChain object instantiated with `@langchain_factory`. This is useful when your agent's `run` method requires custom parameters. The response is not automatically sent to the UI, so remember to send a `Message`.

Also, ensure to specify the appropriate [callback handler](/api-reference/langchain/callbacks) for your agent.

### Parameters

<ParamField path="agent" type="Any">
  The instantiated LangChain agent.
</ParamField>
<ParamField path="input_str" type="str">
  The user input message from the UI.
</ParamField>

### Running an Asynchronous Agent

Use the following code example to run an asynchronous agent:

```python
from langchain import OpenAI, LLMChain, PromptTemplate
import chainlit as cl

prompt_template = "{input}?"

@cl.langchain_factory(use_async=True)
def main():
    llm = OpenAI(temperature=0)
    chain = LLMChain(llm=llm, prompt=PromptTemplate.from_template(prompt_template))
    return chain

@cl.langchain_run
async def run(agent, input_str):
    res = await agent.acall(input_str, callbacks=[cl.AsyncChainlitCallbackHandler()])
    await cl.Message(content=res["text"]).send()
```

### Running a Synchronous Agent

Use the following code example to run a synchronous agent:

```python
from langchain import OpenAI, LLMChain, PromptTemplate
import chainlit as cl

prompt_template = "{input}?"

@cl.langchain_factory(use_async=False)
def main():
    llm = OpenAI(temperature=0)
    chain = LLMChain(llm=llm, prompt=PromptTemplate.from_template(prompt_template))
    return chain

@cl.langchain_run
async def run(agent, input_str):
    res = await cl.asyncify(agent)(input_str, callbacks=[cl.ChainlitCallbackHandler()])
    await cl.Message(content=res["text"]).send()
```

In both examples, the `run` method takes a LangChain agent and user input string as parameters. The agent processes the user input and returns a response that you need to send as a `Message`.
