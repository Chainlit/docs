---
title: "langchain_run"
---

Useful to override the default behavior of the LangChain object instantiated with [@langchain_factory](/api-reference/langchain/langchain-factory).
Use when your agent run method has custom parameters.
Takes the LangChain agent and the user input as parameters.
The response will NOT be automatically sent to the UI, you need to send a [Message](/api-reference/message).

### Parameters

<ParamField path="agent" type="Any">
  The LangChain agent instance
</ParamField>
<ParamField path="input_str" type="str">
  The message coming from the UI.
</ParamField>

### Run a async agent

```python Code Example
from langchain import OpenAI, LLMChain, PromptTemplate
import chainlit as cl

prompt_template = "{input}?"


@cl.langchain_factory(use_async=True)
def main():
    llm = OpenAI(temperature=0)
    chain = LLMChain(llm=llm, prompt=PromptTemplate.from_template(prompt_template))
    return chain


@cl.langchain_run
async def run(agent, input_str):
    res = await agent.acall(input_str, callbacks=[cl.AsyncChainlitCallbackHandler()])
    await cl.Message(content=res["text"]).send()
```

### Run an sync agent

```python Code Example
from langchain import OpenAI, LLMChain, PromptTemplate
import chainlit as cl

prompt_template = "{input}?"


@cl.langchain_factory(use_async=False)
def main():
    llm = OpenAI(temperature=0)
    chain = LLMChain(llm=llm, prompt=PromptTemplate.from_template(prompt_template))
    return chain


@cl.langchain_run
async def run(agent, input_str):
    res = await cl.asyncify(agent)(input_str, callbacks=[cl.ChainlitCallbackHandler()])
    await cl.Message(content=res["text"]).send()
```
