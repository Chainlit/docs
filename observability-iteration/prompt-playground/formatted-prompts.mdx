---
title: Formatted Prompts
---

The formatted prompts view allows you to preview the full text that is sent to the LLM for completion.

There are two ways formatted prompts can be displayed:

1. Read-only: when you configure your prompt with a template and variables
2. Read-write: when you configure your prompt directly with the formatted prompt

## Read-only

When you configure your prompt with a template and variables, the "formatted prompts" view enables you to preview the rendered template. It makes it easy to see the exact text sent to the LLM.

Like in the "Template" view, you can click on the variables to edit them.

This view doesn't let you edit the formatted prompt, as it is only the combination of the template and variables.

When you need to edit the prompt template, go back to the "Template" view.

## Read-write

When you configure your prompt with only a formatted string, the "Template" view is hidden, only the "Formatted prompt" view is available.

Skipping the definition of a template and its variables makes it easier to integrate, although the debugging interface will offer less features (no variable management or template view).

![Formatted Prompt](/images/pp-formatted-prompt.png)

Here is an example of code without the template/variables definitions:

```python
from openai import AsyncOpenAI
import chainlit as cl
from chainlit.prompt import Prompt, PromptMessage
from chainlit.playground.providers import ChatOpenAI

client = AsyncOpenAI(api_key="YOUR_OPENAI_API_KEY")

template = "Hello, {name}!"
inputs = {"name": "John"}

settings = {
    "model": "gpt-3.5-turbo",
    "temperature": 0,
    # ... more settings
}


@cl.on_chat_start
async def start():
    # Create the Chainlit Prompt instance without template and inputs
    prompt = Prompt(
        provider=ChatOpenAI.id,
        settings=settings,
        messages=[
            PromptMessage(
                formatted=template.format(**inputs),
                role="assistant",
            )
        ],
    )

    # Make the call to OpenAI
    response = await client.chat.completions.create(
        messages=[m.to_openai() for m in prompt.messages], **settings
    )

    prompt.completion = response.choices[0].message.content

    await cl.Message(
        content=prompt.completion,
        prompt=prompt,
    ).send()
```
